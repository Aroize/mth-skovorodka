__Измерения в науке__

Чтобы использовать научные методы для получения знания, ученые создают специальные инструменты, наиболее распространенным из которых является измерение\. Измерение, как и научный метод в целом, зависит от теории, которой придерживается ученый, и гипотез, которые он выдвигает на основе этой теории\. Теория — это сформулированная в научных понятиях и соотносящаяся с фактами система утверждений, объясняющих окружающий мир\. Гипотеза — это утверждение, сформулированное так, чтобы его можно было проверить\. Гипотезы — выводимые из теории предсказания относительно результатов научного исследования\. Научное измерение позволяет получать точные данные, которые могут применяться для подтверждения или опровержения гипотез, соотноситься с другими данными и использоваться другими учеными\.

Наука об измерениях называется метрологией\. Измерение заключается в приписывании характеристикам изучаемого объекта, явления или процесса точных показателей, которые можно агрегировать и подвергать математической обработке\. Ученые измеряют температуру, скорость, вес, расстояние, размеры, время и многие другие свойства окружающего мира\. Чтобы приписать некоторое значение измеряемой величине, необходимо использовать эталон и техническое средство, позволяющее соотнести величину с этим эталоном\. Поэтому ученые создают и применяют различные линейки, шкалы, единицы измерения\. В 1875 году была подписана Метрическая конвенция, в результате которой многие страны начали пользоваться метрической системой\. Это имело не только научное, но и большое хозяйственное значение\. Ее продолжением стала принятая в 1960 году Международная система единиц \(СИ\)\. Эти системы заменили «народные меры», которые сильно различались от страны к стране и не были согласованы между собой\.

Главными преимуществами научного измерения являются *стандартизированность* и *точность*\. Ученые пользуются общими единицами измерения, благодаря чему получаемые ими данные сопоставимы\. Точность измерительных инструментов означает уверенность в том, что измеренное и действительное значение некоторой характеристики совпадают\. Ученые постоянно стремятся к повышению точности своих измерений\. Хотя в процессе измерения могут возникать ошибки и погрешности, ученые умеют их выявлять и оценивать\.

Измерение, как и вся наука, развивается\. Современные научные измерения имеют несколько особенностей:

- В ходе измерения широко используется принцип вероятности: ученые стремятся не к абсолютно точному измерению, а к оценке вероятности наличия измеряемой величины\.
- Благодаря распространению вычислительной техники ученые могут получать и обрабатывать огромные массивы данных, что позволяет производить измерения гораздо быстрее, с учетом большего числа параметров, надежнее и точнее\.
- Поскольку большие вычислительные мощности сегодня есть не только у ученых, но и у неспециалистов, в науке все чаще для осуществления вычислений, необходимых для измерения, привлекают обычных людей\. Кроме того, в некоторых областях науки неспециалисты занимаются сбором научных данных, позволяющих производить более масштабные и точные измерения\.

__Базовые понятия__

Единицы измерения и их системы

Для проведения научных измерений необходим набор единых и стандартизированных единиц, позволяющих выразить измеряемую характеристику\. Поскольку наука вырастает из повседневного опыта познания окружающего мира, первоначально в науке использовались те единицы измерения, которые были распространены в обществе и исполняли, прежде всего, хозяйственные функции\. Например, ведение торговли невозможно без измерения расстояний, веса и объема товаров\. Так появились многочисленные «народные» единицы измерения, например русские аршин \(длина человеческого шага\), сажень \(расстояние между кончиками пальцев расставленных в стороны рук\), вершок \(длина основной фаланги указательного пальца\) или французское лье \(расстояние, проходимое за один час пешком\)\. Однако этих единиц измерения были слишком много, их было сложно переводить друг в друга, и они были недостаточно точны, поэтому их использование для научных измерений ограничивало возможности ученых в описании окружающего мира\.

Развитие науки требовало введения единой системы измерений, в основе которой лежали бы не параметры человеческого тела или наблюдаемых природных явлений, а универсальные стандарты, воплощенные в эталонах\. Без такой стандартизации измерений ученые не могли сопоставлять получаемые ими данные и проверять открытия друг друга\. Первой такого рода целостной системой стала принятая во Франции в 1837 году метрическая система\. В основе ее лежали созданные во Франции эталоны килограмма и метра\. В 1875 году к Франции присоединились другие страны \(включая Россию\), которые подписали международную Метрическую конвенцию\.

Применение метрической системы в научных исследованиях до конца XIX века основывалось на так называемой системе СГС \(сантиметр — грамм — секунда\), предложенной в 1832 году немецким ученым Карлом Фридрихом Гауссом и позже доработанной британскими физиками Уильямом Томсоном и Джеймсом Клерком Максвеллом\. По мере развития измерений у этой системы были обнаружены определенные недостатки, для исправления которых была предложена система МКС \(метр — килограмм — секунда\), принятая в 1889 году, хотя и система СГС, и система МКС продолжали использоваться до середины XX века, а система СГС используется до сих пор \(например, в области электродинамики\)\.

Наконец, в 1960 году была принята международная система единиц СИ \(Le Système International d’Unités, SI\), в которую вошла система МКС\. В основе СИ лежат семь основных единиц: единица масса — килограмм, единица длины — метр, единица времени — секунда, единица силы электрического тока — ампер, единица термодинамической температуры — кельвин, единица количества вещества — моль и единица силы света — кандела, которые не сводимы друг к другу, но от которых можно получать производные единицы\. СИ сегодня широко используется в научных исследованиях, хотя ее продолжают совершенствовать\. Изменения в СИ обсуждаются и принимаются на Генеральных конференциях по мерам и весам, организуемых Международным комитетом мер и весом\.

Чтобы единицы измерения можно было использовать, они должны быть соотнесены с неизменным эталоном, каковым первоначально выступали физические объекты, хранящиеся в парижском Международном бюро мер и весом\. Эти объекты продолжают исполнять функцию прототипов международных единиц \(например, эталон килограмма представляет собой цилиндр из сплава платины и иридия диаметром и высотой 39,17 мм\), однако они требует постоянного усовершенствования в силу сложности обеспечения необходимой точности измерений, поэтому в будущем планируется дать новые определения основных единиц измерения, основанные на фиксированных числовых значениях ряда физических констант\. Например, килограмм будет определяться через постоянную Планка, а секунда — через частоту расщепления атома цезия\-133\.

Различные науки создают собственные единицы, соответствующие их исследовательским задачам\. При помощи этих единиц ученые получают такие описания изучаемых объектов и явлений, которые могут быть проверены другими учеными, сопоставлены с полученными ранее данными и соотнесены с гипотезами и предсказаниями, выводимыми из имеющихся теорий\.

Наравне с метрическим шкалами, предполагающими использование единиц измерений, в науке используются и неметрические шкалы, в основе которых лежат не единицы измерений, а способы классификации объектов на основе качественных признаков\. Например, в системе классификации растений, предложенной шведским ученым Карлом Линнеем в 1735 году в книге «Система природы», используются такие характеристики растений, как число, размер и расположение пестиков и тычинок и способы разделения полов у растений\. А в опросах общественного мнения часто используются так называемые порядковые шкалы, например: полностью доволен / очень доволен / достаточно доволен / достаточно недоволен / очень недоволен\.

Точность измерения

Точность измерения означает уверенность ученого в том, что измеренное и действительное значение некоторой характеристики совпадают\. Повышение точности измерений составляет отличительный признак развития научного знания\. Одной из первых наук, продемонстрировавших огромное значение точности измерений для науки, стала астрономия\. Научная революция XVII века была обеспечена во многом точными измерениями движения небесных тел, для объяснения которых формулировались физические законы и теории\. По мере развития науки ученые создавали и использовали как необходимые единицы измерения, так и инструменты, позволяющие повышать точность измерений\. Например, для измерения массы газов требовались особые устройства, позволявшие делать научные открытия\. В конце XVIII века Бенджамин Томпсон опроверг существование теплорода \(субстанции, которая считалась носителем теплоты\), показав, что теплота не имеет массы\.

Принято разделять точность средства измерения и точность результата измерения\. Точность средства измерения означает соответствие показаний измерительного прибора и действительного значение измеряемой характеристики, а точность результата измерения — близость результатов серии измерений друг другу, различия между которыми должны стремиться к нулю\. Если взять серию измерений определенной постоянной характеристики \(например, температуры\), то точность средства измерения будет означать близость каждого отдельного измерения к истинному значению \(близость измеренной температуры реальной\), а точность результата измерения — близость отдельных измерений между собой \(насколько совпадает измеренная в разное время температура\)\.

Необходимо помнить, что в науке истинное значение измеряемой характеристики никогда не известно, поэтому необходимо рассматривать точность средства измерения не как соответствие между результатом измерения и реальностью, а как согласованность значений, приписываемых определенной характеристике исходя из полученных данных и рада теоретических допущений\. Данную проблему можно проиллюстрировать следующим примером\. Если первоначально у нас есть термометр, измеряющего температуру с точностью до 1 градуса, как можно оценить точность измерения термометра, измеряющего температуру с точностью до 0,1 градуса? Точность «более точного» инструмента в данном случае основывается на признании точности «менее точного» инструмента\. В таком случае, точность измерений основывается не на соответствии реальности, а на моделях, описывающих процесс измерения\. Точное измерение — это оценка наилучшего, наиболее вероятного значения измеряемой величины\.

Проблема точности измерения стоит особенно остро перед социальными науками, которые в основном имеют дело с качественными, а не количественными признаками\. В социальных науках измерение в целом гораздо больше зависит от теоретического и ценностного выбора исследователя и, поскольку социальные феномены нельзя наблюдать непосредственно, предполагает использование данных, полученных в результате описания социальных процессов их участниками\. Кроме того, в социальных науках сам факт измерения может менять измеряемое качество\. Например, в случае социологического опроса необходимо учитывать возможность социально желательных ответов, когда респондент дает ответы, которые, по ее или его мнению, от него ожидает исследователь\. Все эти обстоятельства делают достижение точности измерения в социальных науках более сложным, чем в науках, имеющих дело с квантифицируемыми характеристиками окружающего мира\.

Погрешность измерения

Погрешностью измерения принято называть степень расхождения между истинным значением измеряемой величины и результатом ее измерения\. Поскольку измерение в современной науке — процесс, иногда требующий использования сложного оборудования, главная задача ученого в процессе измерения — удостовериться, что особенности этого процесса не привели к отклонению результата измерения от действительного значения измеряемой величины\.

В последнее время в метрологии вместо понятия «погрешность» принято использовать понятие «неопределенность»\. В 1993 году Объединенный комитет по руководствам в области метрологии выпустил «Руководство по выражению неопределенности измерения», в котором предлагается отказаться от понятий «истинное значение» и «погрешность измерения»\. Вместо них вводится понятие «неопределенность измерения», которое определяется как параметр, относящийся к результату измерения и характеризующий разброс значений, которые могли бы быть обоснованно приписаны измеряемой величине\. Иными словами, неопределенность указывает на степень сомнения, которое остается у исследователя после проведения измерения\. В таком случае, точность измерения — это мера «кучности» при серии «попаданий в мишень», а неопределенность — мера разброса результатов отдельных «выстрелов»\. При этом понятие «погрешности» остается, однако получает узкое значение\. «Погрешность» относится к процедуре измерения и может быть оценена, например, когда результаты измерения сравниваются с эталоном, неопределенностью которого можно пренебречь\.

Погрешность принято разделять на систематическую и случайную\. Систематическая погрешность проявляется регулярно в серии измерений и поэтому можно вычислить ее причину, установив закономерность, с которой она появляется\. Систематическая погрешность может быть вызвана, например, сбоем измерительного оборудования\. Систематическую погрешность измерения можно компенсировать, введя поправочный коэффициент\. Случайная погрешность появляется непредсказуемым образом и может отсутствовать при повторных измерениях\. Влияние случайных погрешностей можно компенсировать увеличением количества измерений, так как усреднение получаемых результатов позволяет снизить эффект искажений, вносимых случайными факторами\.

Кроме того, можно разделять погрешности по источнику их происхождения: источником может быть исследователь, измерительное оборудование, объект измерения или какие\-то особенности обстановки, в которой осуществляется измерение\.

«Руководство по выражению неопределенности измерения» сегодня является основным документом, регламентирующим измерения в науке\. В нем вводятся различные типа неопределенности измерения, указываются ее источники, описываются процедуры оценки неопределенности\. По сути «Руководство» предлагает отказаться от понимания точности и погрешности измерения, основанного на возможности установления истинного и абсолютного значения измеряемой величины, и рассматривать измерение как вероятностный процесс, результаты которого указывают на степень уверенности исследователя в достоверности полученных данных\.

Рост вычислительных мощностей

Современные научные измерения требуют больших вычислительных мощностей\. Например, для обработки данных, получаемых на Большом адронном коллайдере \(БАК\), создана специальная компьютерная сеть LCG \(LHC Computing Grid\), в которую входит, по состоянию на 2017 год, 170 вычислительных центров из 42 стран\. На данный момент это крупнейшая в мире сеть, построенная по технологии «грид» \(т\.е\. без центрального вычислительного узла\)\. Объем получаемых данных на БАК настолько велик, что для их обработки был запущен проект LHC@Home, в рамках которого добровольцы производят необходимые вычисления на своих домашних компьютерах\. Хотя БАК — уникальная научная установка, в других областях науки измерения тоже требуют значительных вычислительных мощностей\. Это касается не только естественных наук, но и наук социальных и гуманитарных\. Например, в последние году получило развитие такое направление, как «цифровые гуманитарные науки», которые предполагают применение методов истории, лингвистики, литературоведения, музыковедения и т\.д\. к цифровых данным \(видеозаписям, аудиозаписям, цифровым фотографиям\), что предполагает проведение специальных вычислений\.

Сегодня развитие научных исследований в целом и научных измерений в частности во многом зависит от развития вычислительных мощностей\. Это обусловлено несколькими факторами\. Во\-первых, компьютеры становятся все более доступными и дешевыми и одновременно повышается их мощность\. Во\-вторых, появляется все больше способов хранения данных, как в распределенных хранилищах, как и на персональных компьютерах\. Хранение данных становится более дешевым, а хранилища — более вместительными\. В\-третьих, увеличиваются пропускная способность и скорость передачи данных по каналам связи\. Распространяется беспроводной интернет, становится более распространенной и доступной мобильная передача данных\. Наконец, создаются протоколы связи и программное обеспечение, позволяющие производить распределенные вычисления и обеспечивающие совместимость разных типов данных\.

Можно выделить несколько направлений дальнейшей эволюции вычислений, обеспечивающих измерения в науке\. Прежде всего, развиваются и будут развиваться технологии машинного обучения\. Машинное обучение позволяет структурировать результаты измерения, вычленить в огромном массиве данных те, которые представляют ценность, и устанавливать связи, обнаружение которых без соответствующих алгоритмов было бы длительным или невозможным\. Будет также развиваться такое направление, как разработка самоадаптирующихся систем, т\.е\. компьютерных систем, способных отслеживать непредвиденные изменения в изучаемом объекте и адаптироваться к ним\. Далее, будут разрабатываются методы измерения, основанные на моделировании\. Некоторые физические процессы необходимо изучать, сначала моделируя их поведение, а затем измеряя параметры реальных систем\. В этом случае оценка измеряемой величины зависит не только от неопределенности получаемых данных, но и от чувствительности этих данных к параметрической модели\. Построение таких моделей требует специальных технологий и больших вычислительных мощностей\. Развитие вычислительных технологий также может оказать существенную помощь в оценке неопределенности научных измерений, поскольку часто изучаемые системы настолько сложны и на процесс измерения может влиять столько факторов, что необходимы масштабные вычисления и специальные алгоритмы для выявления погрешностей измерения и оценки неопределенности результатов измерения\. Еще одно направления применения компьютерных технологий в научных измерениях — метаописание результатов измерения\. Измерения могут давать данные, имеющие разные источники и используемые в разных исследовательских целях, поэтому приписывание результатам измерения метаданных позволяет сделать их более удобными для дальнейшего использования и обеспечивает их целостность и связность\.

Развитие вычислительных технологий позволяет ученым не только собирать более обширные и разнообразные данные в процессе измерения, но и представлять результаты измерения ранее невозможными способами, например в виде трехмерных моделей или посредством других форм визуализации\.

__Законы__

Разнообразие мер длины и веса

Исторически первые меры длины и веса были привязаны к доступным и простым стандартам, прежде всего — к человеческому телу\. Несмотря на то, что параметры человеческих тел никогда не совпадают с абсолютной точностью, их разнообразие достаточно низко, чтобы создавать меры, удобные в хозяйстве\. Так появился английский дюйм \(ширина большого пальца\), русская пядь \(расстояние между кончиками разведенных большого и указательного пальцев\), французский туаз \(расстояние между кончиками пальцев вытянутых рук\)\. Помимо параметров человеческого тела источником мер длины и веса была хозяйственная деятельность человека \(например, русская верста — это длина борозды, которую способен пройти вол, не утомляясь, а золотник — мера веса, равная весу одноименной золотой монеты\)\. По мере развития науки становилось очевидно, что эти меры не подходят для научных измерений в силу их разнообразие и неточности\. Для разработки мер начали применять научные методы наблюдение\. Например, в 1791 году во Франции было принято решение считать метром одну десятимиллионную часть расстояния от Северного полюса до экватора, измеренного по парижскому меридиану\. В 1792–1797 годах два французских исследователя измерили дугу парижского меридиана от Дюнкерка до Барселоны и установили точное значение метра\. Сегодня меры длины, веса и других единиц измерения соотносятся со специальными эталонами, хранящимися в Международном бюро мер и весов, однако в будущем они будут соотносятся не с физическими объектами, а постоянными физическими величинами, вроде скорости света, постоянной Планка, постоянной Больцмана, числом Авогадро и др\.

Аксиомы метрологии

Аксиомы метрологии были сформулированы российским метрологом Игорем Федоровичем Шишкиным\. Они таковы\.

*Аксиома 1\.* Без априорной информации измерение невозможно\. Это означает, что мы должны обладать определенной информацией об измеряемой величине прежде, чем проведем измерение\. В случае полного отсутствия информации или полной информации о величине измерение ничего не даст\. Измерение — это утонение значения измеряемой величины\.

*Аксиома 2\.* Измерение суть сравнение размеров опытным путем\. Для измерение должны иметься две величины, одна из которых сравнивается с другой\. Способ сравнения при этом может быть любой\.

*Аксиома 3\.* Результат измерения без округления является случайным\. На измеряемую величину влияет множество факторов, точный учет которых невозможен, поэтому результат измерения всегда случаен\. При многократных измерениях какой\-либо величины всегда будут получаться различающиеся оценки, которые можно сделать одинаковыми, лишь округлив\.

Репрезентативность данных

Репрезентативность данных — термин, обозначающий способность определенной совокупности данных \(их называют выборочные данные или выборка\) представлять \(репрезентировать\) весь набор случаев \(генеральную совокупность\), частью которого эти данные являются\. Поскольку далеко не всегда есть возможность изучить всю совокупность некоторых случаев \(например, все электроны во вселенной или каждого жителя России\), существуют специальные процедуры, обеспечивающие возможность экстраполировать результаты измерения небольшой части общего числа случаев на генеральную совокупность\. Обеспечение репрезентативности данных предполагает, что ученые выбирает такой набор случаев, которые отражают интересующие его особенности всей совокупности, из которой производится выбор\.

Метод Корнфельда

Метод Корнфельда для оценки погрешности измерения был предложен американским специалистом по статистике Джеромом Корнфельдом \(Jerome Cornfield, 1912–1979\)\. Это относительно простой метод установления погрешности измерения\. Метод состоит в следующем\. Если проведена серия из *n* измерений некоторого параметра *x* и при каждом измерении получено значение *xi* измеряемого параметра, среднее арифметическое этих измерений \(\) будет, скорее всего, близко к истинному значению измеряемой величины\. Погрешность измерения \(∆*x*\) — отклонение результата измерения от истинного значения\. Интервал, в пределах которого может оказаться истинное значение измеряемой величины, называют доверительным интервалом \( ± ∆*x*\)\. В методе Корнфельда предполагается, что доверительный интервал соответствует интервалу между минимальным и максимальным значениями измеряемого параметра в серии измерений, т\.е\.  – ∆*x* = *х*мин и  \+ ∆*x* = *х*макс\. Следовательно,

 = ,

а погрешность вычисляется по формуле:

∆*x *= 

__Имена__

Давление и барометры

Научные инструменты для измерения свойств окружающего мира позволили сделать науку систематической процедурой по производству знаний, не зависящих от мнений отдельных ученых и от повседневного опыта\. Например, изобретение барометра позволило показать, что у воздуха есть вес, хотя до этого считалось, что воздух невесом\. Аристотель полагал, что поршень насоса способен поднимать воду, потому что природа не терпит пустоты\. Однако в XVII веке было доказано, что это не так\. Первый ртутный барометр был создан итальянским математиком и физиком Эванджелиста Торричелли \(Evangelista Torricelli, 1608–1647\) в 1644 году\. Торричелли и выдвинул предположение о наличии у воздуха веса\. 

Измерение скорости

По мере развития науки ученые создавали устройства, позволяющие измерять скорости объектов, недоступные для человеческих органов восприятия\. Мы все может заметить движение падающего яблока и оценить его относительную скорость в отдельный момент времени \(в сравнении с обстановкой или другими падающими предметами\)\. Но чтобы заметить и оценить ускорение падения, нам необходимы специальные наблюдения, желательно — в лабораторной обстановке\. Создаваемые учеными экспериментальные ситуации позволяют измерить скорость даже тех объектов, которые человек никогда не сможет наблюдать в движении, например звука и света\.

Скорость звука была впервые измерена Уильямом Деремом \(William Derham, 1657–1735\), английским священником и физиком\. Стоя на крыше церкви, он измерял, за какое время до него дойдет звук выстрела из пушки, находящейся в 19 километрах от церкви\. Вычислив среднее значение результатов серии измерений, он получил значение скорости звука в воздухе, достаточно близкое к современному\.

Скорость света была впервые измерена в земных условиях в 1849 году французским физиком Арманом Физо \(Armand\-Hippolyte\-Louis Fizeau, 1819–1896\) с помощью зубчатого диска\. В 1851 году он предложил метод определения скорости света путем пропускания пучков света через трубы с неподвижной и с текущей водой с целью определения влияния скорости воды на скорость света\.

Измерение кислотности

Кислотность обозначает степень концентрации ионов водорода в определенной среде и обозначается как pH\. Впервые это обозначение было введено в 1909 году датским химиком Сёреном Сёренсоном \(Søren Sørensen, 1868–1939\)\. На основе исследований Сёренсона сейчас создаются различные pH\-метры, используемые в самых разных отраслях науки, медицины и промышленности\.

Измерение энергии элементарных частиц и гравитационных волн

Для некоторых измерений используются несистемные единицы, например электронвольт \(эВ\) — единица, применяемая для оценки энергии элементарных частиц\. Один электронвольт — это энергия, необходимая для перемещения электрона в электрическом поле между точками с разностью потенциалов в 1 вольт\. Фотоны в оптическом диапазоне имеют энергию около 2 эВ, а энергия протон\-протонных столкновений достигает нескольких миллиардов электронвольт\. Электронвольтами обозначают не только энергию, но и массу элементарных частиц, а также иногда температуру\. В физике элементарных частиц измерение их энергии позволяет изучать строение материи\. Один из распространенных методов — разгон элементарных частиц в ускорителе и их столкновение, в результате которого появляются новые частицы\. Изучение последствий столкновения \(какие частицы появились, какова их энергия и т\.д\.\) позволяет изучать свойства исходных частиц\.

Измеримой энергией обладают не только элементарные частицы, но и гравитационные волны\. Открытие гравитационных волн в 2016 году стало возможным благодаря тому, что ученые «охотились» за волнами с высокой энергией, возникающими в результате столкновения черных дыр\.

1837 год\. Введение метрической системы

В 1837 году во Франции была введена метрическая система\. До этого в годы Французской революции уже предпринималась попытка ее внедрения, однако она закончилась неудачей\. Различные виды метрических систем вводились ранее и в других странах, однако именно после перехода Франции на метрическую систему она начала стремительно распространяться по всей Европе и в 1875 году семнадцатью странами была подписана Метрическая конвенция\.

1960 год\. Международная система единиц СИ

В 1960 году на XI Генеральной конференции по мерам и весам была принята Международная система единиц \(СИ\), в которой определялись 7 основных единиц измерения \(килограмм, метр, секунда, ампер, кельвин, моль, кандела\), от которых можно образовывать другие единицы\. Сегодня СИ является основной системой единиц в науке, хотя существуют и другие системы\.

Триангуляция как основа современной картографии

Триангуляция — метод геодезии, заключающийся в создании сети геодезических пунктов с помощью расположения на местности смежных треугольников, в которых определяется длина одной из сторон и величины двух углов, что позволяет устанавливать длины остальных двух сторон\. Триангуляцией называют и метод построения такой сети, и саму эту сеть\. Триангуляция позволяет создавать точные карты местности\. Впервые с этой целью ее использовал фламандский картограф Герард Меркатор \(Gerhardus Mercator, 1512–1594\) в XVI веке\.

